{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thiago de Sousa - 374204 e Gabriel Gomes - 374178"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        ''' Default Constructor '''\n",
    "        self.lEncoder = LabelEncoder()\n",
    "        self.X = None; self.y = None\n",
    "        self.classProb = None; self.likeTable = {}\n",
    "    \n",
    "    def separateByClass(self):\n",
    "        ''' This functions separates all the dataset indexing dictionaries by the classes '''\n",
    "        separated = {}\n",
    "        for i in range(len(self.y)):\n",
    "            if (self.y[i] not in separated):\n",
    "                separated[self.y[i]] = []\n",
    "            separated[self.y[i]].append(self.X[i])\n",
    "        return separated\n",
    "    \n",
    "    def makeLikeTable(self):\n",
    "        ''' This functions counts the occurences of each attribute based on the classes\n",
    "        and construct the Likelihood table (in this case a Dictionary) calculating all\n",
    "        the propers probabilities '''\n",
    "        sepClass = self.separateByClass()\n",
    "        classSizes = [len(sepClass[i]) for i in sepClass.keys()] \n",
    "        self.classProb = np.array(classSizes) / sum(classSizes)\n",
    "        \n",
    "        self.likeTable = {}\n",
    "        for label in sepClass.keys():\n",
    "            aux = np.column_stack(sepClass[label])\n",
    "            for attribute,idx in zip(aux, range(len(aux))):\n",
    "                counts = np.asarray(np.unique(attribute, return_counts=True)).T\n",
    "                for i in range(4):\n",
    "                    self.likeTable[(label, idx, i)] = 0\n",
    "                for count_it in counts:\n",
    "                    self.likeTable[(label, idx, count_it[0])] = count_it[1] / len(sepClass[label])\n",
    "\n",
    "    def calculateProbability(self, inputVector):\n",
    "        ''' Utilizes the maximum likelihood estimation to calculate the probabilty of\n",
    "        each row in inputVector belongs to each possible class '''\n",
    "        sepClass = self.separateByClass()\n",
    "        \n",
    "        probabilities = {}\n",
    "        for label,_ in sepClass.items():\n",
    "            probabilities[label] = self.classProb[label]\n",
    "            for i in range(len(inputVector)):\n",
    "                probabilities[label] *= self.likeTable[label, i, inputVector[i]]\n",
    "                \n",
    "        return probabilities\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        ''' Assign the training data and calls the Likelihood Table creator '''\n",
    "        self.X = X_train\n",
    "        self.y = y_train\n",
    "        \n",
    "        self.makeLikeTable()\n",
    "    \n",
    "    def predict(self, inputArray):\n",
    "        ''' Return a list of predictions for each row in inputArray correspondent to\n",
    "        the label of the class with the maximum probability '''\n",
    "        predictions = []\n",
    "        for row in inputArray:\n",
    "            probabilities = self.calculateProbability(row)\n",
    "            predictions.append(max(probabilities, key=probabilities.get))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"carData.csv\", header=None)\n",
    "\n",
    "\n",
    "for i in range(0, data.shape[1]):\n",
    "    data.iloc[:,i] = LabelEncoder().fit_transform(data.iloc[:,i])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes (Versão do Sklearn)\n",
      "Acurácia Total:: 0.7109826589595376%\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      unacc       1.00      0.04      0.08        75\n",
      "        acc       0.00      0.00      0.00        16\n",
      "       good       0.71      1.00      0.83       243\n",
      "      vgood       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.71      0.71      0.60       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petcomp1/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "y_pred = clf.predict(X_test.values)\n",
    "\n",
    "\n",
    "print(\"Multinomial Naive Bayes (Versão do Sklearn)\")\n",
    "print(\"Acurácia Total:: {}%\".format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=[\"unacc\", \"acc\", \"good\", \"vgood\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (Nossa Versão)\n",
      "Acurácia Total: 0.838150289017341%\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      unacc       0.63      0.68      0.65        75\n",
      "        acc       0.50      0.19      0.27        16\n",
      "       good       0.92      0.95      0.93       243\n",
      "      vgood       0.75      0.50      0.60        12\n",
      "\n",
      "avg / total       0.83      0.84      0.83       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nBayes = NaiveBayes()\n",
    "nBayes.fit(X_train.values, y_train.values)\n",
    "y_pred = nBayes.predict(X_test.values)\n",
    "\n",
    "print(\"Naive Bayes (Nossa Versão)\")\n",
    "print(\"Acurácia Total: {}%\".format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=[\"unacc\", \"acc\", \"good\", \"vgood\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
