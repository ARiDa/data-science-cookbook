{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Trabalho\n",
    "### Aluno : Joel Oliveira Ribeiro - 371822\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import de bibliotecas \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import math \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "Implementar um classifacor Naive Bayes para o problema de predizer a qualidade de um carro. Para este fim, utilizar um conjunto de dados referente a qualidade de carros, disponível no [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Carregando o dataFrame e tratando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      vhigh vhigh.1      2   2.1  small   low  unacc\n",
      "0     vhigh   vhigh      2     2  small   med  unacc\n",
      "1     vhigh   vhigh      2     2  small  high  unacc\n",
      "2     vhigh   vhigh      2     2    med   low  unacc\n",
      "3     vhigh   vhigh      2     2    med   med  unacc\n",
      "4     vhigh   vhigh      2     2    med  high  unacc\n",
      "5     vhigh   vhigh      2     2    big   low  unacc\n",
      "6     vhigh   vhigh      2     2    big   med  unacc\n",
      "7     vhigh   vhigh      2     2    big  high  unacc\n",
      "8     vhigh   vhigh      2     4  small   low  unacc\n",
      "9     vhigh   vhigh      2     4  small   med  unacc\n",
      "10    vhigh   vhigh      2     4  small  high  unacc\n",
      "11    vhigh   vhigh      2     4    med   low  unacc\n",
      "12    vhigh   vhigh      2     4    med   med  unacc\n",
      "13    vhigh   vhigh      2     4    med  high  unacc\n",
      "14    vhigh   vhigh      2     4    big   low  unacc\n",
      "15    vhigh   vhigh      2     4    big   med  unacc\n",
      "16    vhigh   vhigh      2     4    big  high  unacc\n",
      "17    vhigh   vhigh      2  more  small   low  unacc\n",
      "18    vhigh   vhigh      2  more  small   med  unacc\n",
      "19    vhigh   vhigh      2  more  small  high  unacc\n",
      "20    vhigh   vhigh      2  more    med   low  unacc\n",
      "21    vhigh   vhigh      2  more    med   med  unacc\n",
      "22    vhigh   vhigh      2  more    med  high  unacc\n",
      "23    vhigh   vhigh      2  more    big   low  unacc\n",
      "24    vhigh   vhigh      2  more    big   med  unacc\n",
      "25    vhigh   vhigh      2  more    big  high  unacc\n",
      "26    vhigh   vhigh      3     2  small   low  unacc\n",
      "27    vhigh   vhigh      3     2  small   med  unacc\n",
      "28    vhigh   vhigh      3     2  small  high  unacc\n",
      "29    vhigh   vhigh      3     2    med   low  unacc\n",
      "...     ...     ...    ...   ...    ...   ...    ...\n",
      "1697    low     low      4  more    big   low  unacc\n",
      "1698    low     low      4  more    big   med   good\n",
      "1699    low     low      4  more    big  high  vgood\n",
      "1700    low     low  5more     2  small   low  unacc\n",
      "1701    low     low  5more     2  small   med  unacc\n",
      "1702    low     low  5more     2  small  high  unacc\n",
      "1703    low     low  5more     2    med   low  unacc\n",
      "1704    low     low  5more     2    med   med  unacc\n",
      "1705    low     low  5more     2    med  high  unacc\n",
      "1706    low     low  5more     2    big   low  unacc\n",
      "1707    low     low  5more     2    big   med  unacc\n",
      "1708    low     low  5more     2    big  high  unacc\n",
      "1709    low     low  5more     4  small   low  unacc\n",
      "1710    low     low  5more     4  small   med    acc\n",
      "1711    low     low  5more     4  small  high   good\n",
      "1712    low     low  5more     4    med   low  unacc\n",
      "1713    low     low  5more     4    med   med   good\n",
      "1714    low     low  5more     4    med  high  vgood\n",
      "1715    low     low  5more     4    big   low  unacc\n",
      "1716    low     low  5more     4    big   med   good\n",
      "1717    low     low  5more     4    big  high  vgood\n",
      "1718    low     low  5more  more  small   low  unacc\n",
      "1719    low     low  5more  more  small   med    acc\n",
      "1720    low     low  5more  more  small  high   good\n",
      "1721    low     low  5more  more    med   low  unacc\n",
      "1722    low     low  5more  more    med   med   good\n",
      "1723    low     low  5more  more    med  high  vgood\n",
      "1724    low     low  5more  more    big   low  unacc\n",
      "1725    low     low  5more  more    big   med   good\n",
      "1726    low     low  5more  more    big  high  vgood\n",
      "\n",
      "[1727 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Carregando o dataFrame\n",
    "df = pd.read_csv(\"carData.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      vhigh  vhigh.1      2   2.1  small  low  unacc\n",
      "0         0        0      2     2      0    0      0\n",
      "1         0        0      2     2      0    1      0\n",
      "2         0        0      2     2      1    2      0\n",
      "3         0        0      2     2      1    0      0\n",
      "4         0        0      2     2      1    1      0\n",
      "5         0        0      2     2      2    2      0\n",
      "6         0        0      2     2      2    0      0\n",
      "7         0        0      2     2      2    1      0\n",
      "8         0        0      2     4      0    2      0\n",
      "9         0        0      2     4      0    0      0\n",
      "10        0        0      2     4      0    1      0\n",
      "11        0        0      2     4      1    2      0\n",
      "12        0        0      2     4      1    0      0\n",
      "13        0        0      2     4      1    1      0\n",
      "14        0        0      2     4      2    2      0\n",
      "15        0        0      2     4      2    0      0\n",
      "16        0        0      2     4      2    1      0\n",
      "17        0        0      2  more      0    2      0\n",
      "18        0        0      2  more      0    0      0\n",
      "19        0        0      2  more      0    1      0\n",
      "20        0        0      2  more      1    2      0\n",
      "21        0        0      2  more      1    0      0\n",
      "22        0        0      2  more      1    1      0\n",
      "23        0        0      2  more      2    2      0\n",
      "24        0        0      2  more      2    0      0\n",
      "25        0        0      2  more      2    1      0\n",
      "26        0        0      3     2      0    2      0\n",
      "27        0        0      3     2      0    0      0\n",
      "28        0        0      3     2      0    1      0\n",
      "29        0        0      3     2      1    2      0\n",
      "...     ...      ...    ...   ...    ...  ...    ...\n",
      "1697      3        3      4  more      2    2      0\n",
      "1698      3        3      4  more      2    0      3\n",
      "1699      3        3      4  more      2    1      2\n",
      "1700      3        3  5more     2      0    2      0\n",
      "1701      3        3  5more     2      0    0      0\n",
      "1702      3        3  5more     2      0    1      0\n",
      "1703      3        3  5more     2      1    2      0\n",
      "1704      3        3  5more     2      1    0      0\n",
      "1705      3        3  5more     2      1    1      0\n",
      "1706      3        3  5more     2      2    2      0\n",
      "1707      3        3  5more     2      2    0      0\n",
      "1708      3        3  5more     2      2    1      0\n",
      "1709      3        3  5more     4      0    2      0\n",
      "1710      3        3  5more     4      0    0      1\n",
      "1711      3        3  5more     4      0    1      3\n",
      "1712      3        3  5more     4      1    2      0\n",
      "1713      3        3  5more     4      1    0      3\n",
      "1714      3        3  5more     4      1    1      2\n",
      "1715      3        3  5more     4      2    2      0\n",
      "1716      3        3  5more     4      2    0      3\n",
      "1717      3        3  5more     4      2    1      2\n",
      "1718      3        3  5more  more      0    2      0\n",
      "1719      3        3  5more  more      0    0      1\n",
      "1720      3        3  5more  more      0    1      3\n",
      "1721      3        3  5more  more      1    2      0\n",
      "1722      3        3  5more  more      1    0      3\n",
      "1723      3        3  5more  more      1    1      2\n",
      "1724      3        3  5more  more      2    2      0\n",
      "1725      3        3  5more  more      2    0      3\n",
      "1726      3        3  5more  more      2    1      2\n",
      "\n",
      "[1727 rows x 7 columns]\n",
      "--------------------\n",
      "      vhigh  vhigh.1  2  2.1  small  low  unacc\n",
      "0         0        0  0    0      0    0      0\n",
      "1         0        0  0    0      0    1      0\n",
      "2         0        0  0    0      1    2      0\n",
      "3         0        0  0    0      1    0      0\n",
      "4         0        0  0    0      1    1      0\n",
      "5         0        0  0    0      2    2      0\n",
      "6         0        0  0    0      2    0      0\n",
      "7         0        0  0    0      2    1      0\n",
      "8         0        0  0    1      0    2      0\n",
      "9         0        0  0    1      0    0      0\n",
      "10        0        0  0    1      0    1      0\n",
      "11        0        0  0    1      1    2      0\n",
      "12        0        0  0    1      1    0      0\n",
      "13        0        0  0    1      1    1      0\n",
      "14        0        0  0    1      2    2      0\n",
      "15        0        0  0    1      2    0      0\n",
      "16        0        0  0    1      2    1      0\n",
      "17        0        0  0    2      0    2      0\n",
      "18        0        0  0    2      0    0      0\n",
      "19        0        0  0    2      0    1      0\n",
      "20        0        0  0    2      1    2      0\n",
      "21        0        0  0    2      1    0      0\n",
      "22        0        0  0    2      1    1      0\n",
      "23        0        0  0    2      2    2      0\n",
      "24        0        0  0    2      2    0      0\n",
      "25        0        0  0    2      2    1      0\n",
      "26        0        0  1    0      0    2      0\n",
      "27        0        0  1    0      0    0      0\n",
      "28        0        0  1    0      0    1      0\n",
      "29        0        0  1    0      1    2      0\n",
      "...     ...      ... ..  ...    ...  ...    ...\n",
      "1697      3        3  2    2      2    2      0\n",
      "1698      3        3  2    2      2    0      3\n",
      "1699      3        3  2    2      2    1      2\n",
      "1700      3        3  3    0      0    2      0\n",
      "1701      3        3  3    0      0    0      0\n",
      "1702      3        3  3    0      0    1      0\n",
      "1703      3        3  3    0      1    2      0\n",
      "1704      3        3  3    0      1    0      0\n",
      "1705      3        3  3    0      1    1      0\n",
      "1706      3        3  3    0      2    2      0\n",
      "1707      3        3  3    0      2    0      0\n",
      "1708      3        3  3    0      2    1      0\n",
      "1709      3        3  3    1      0    2      0\n",
      "1710      3        3  3    1      0    0      1\n",
      "1711      3        3  3    1      0    1      3\n",
      "1712      3        3  3    1      1    2      0\n",
      "1713      3        3  3    1      1    0      3\n",
      "1714      3        3  3    1      1    1      2\n",
      "1715      3        3  3    1      2    2      0\n",
      "1716      3        3  3    1      2    0      3\n",
      "1717      3        3  3    1      2    1      2\n",
      "1718      3        3  3    2      0    2      0\n",
      "1719      3        3  3    2      0    0      1\n",
      "1720      3        3  3    2      0    1      3\n",
      "1721      3        3  3    2      1    2      0\n",
      "1722      3        3  3    2      1    0      3\n",
      "1723      3        3  3    2      1    1      2\n",
      "1724      3        3  3    2      2    2      0\n",
      "1725      3        3  3    2      2    0      3\n",
      "1726      3        3  3    2      2    1      2\n",
      "\n",
      "[1727 rows x 7 columns]\n",
      "--------------------\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 1 2 0]\n",
      " ..., \n",
      " [3 3 3 ..., 2 2 0]\n",
      " [3 3 3 ..., 2 0 3]\n",
      " [3 3 3 ..., 2 1 2]]\n"
     ]
    }
   ],
   "source": [
    "# Tratamento dos dados, necessário passar algumas features de caracteres para números\n",
    "df['vhigh'] = pd.factorize(df['vhigh'])[0]\n",
    "df['vhigh.1'] = pd.factorize(df['vhigh.1'])[0]\n",
    "df['small'] = pd.factorize(df['small'])[0]\n",
    "df['low'] = pd.factorize(df['low'])[0]\n",
    "df['unacc'] = pd.factorize(df['unacc'])[0]\n",
    "\n",
    "print(df)\n",
    "\n",
    "df['2'] = pd.factorize(df['2'])[0]\n",
    "df['2.1'] = pd.factorize(df['2.1'])[0]\n",
    "\n",
    "print('--------------------')\n",
    "print(df)\n",
    "\n",
    "# Mudando para tipo numpy array\n",
    "df = df.values\n",
    "print('--------------------')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Criando as funções para o classificador do tipo Naive Bayes\n",
    "Adaptando as funções do próprio notebook da aula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "        \n",
    "    return [trainSet, copy]\n",
    "    \n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    " \n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "    \n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "    \n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "    \n",
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * math.pow(stdev, 2))) * exponent\n",
    "    \n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "    \n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "    \n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "    \n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando treino (67%) de teste (33%)\n",
    "X_train,X_test = splitDataset(df,0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.4935177182368193, 1.1095688643707255), (1.497839239412273, 1.1056807537218771), (1.5073465859982713, 1.1095634736654678), (1.0051858254105446, 0.81506622156905), (1.0008643042350907, 0.8230035798648657), (1.0121002592912705, 0.8096683269265)]\n",
      "--------------------------------------------------------\n",
      "{0: [(1.3506815365551426, 1.1215004157709034), (1.3605947955390334, 1.1105555550338533), (1.4745972738537794, 1.1167733364496824), (0.78934324659231725, 0.8306984952291961), (0.92812887236679054, 0.8274384780660208), (1.1970260223048328, 0.8495166210242404)], 1: [(1.5521235521235521, 1.0039579271859078), (1.5945945945945945, 1.0462788110792012), (1.5598455598455598, 1.0922957720211002), (1.501930501930502, 0.5009643210501636), (1.1158301158301158, 0.8033966085081455), (0.53281853281853286, 0.4998877489153622)], 3: [(2.6222222222222222, 0.49031014715590004), (2.6666666666666665, 0.4767312946227963), (1.4888888888888889, 1.1000459127241053), (1.4666666666666666, 0.5045249791095131), (1.0, 0.7977240352174656), (0.46666666666666667, 0.5045249791095131)], 2: [(2.5652173913043477, 0.5012062743707417), (2.2173913043478262, 0.727645929717068), (1.8043478260869565, 1.0670741975116678), (1.5434782608695652, 0.503610155185335), (1.6304347826086956, 0.48802074874715046), (1.0, 0.0)]}\n"
     ]
    }
   ],
   "source": [
    "summ = summarize(X_train)\n",
    "print(summ)\n",
    "print('--------------------------------------------------------')\n",
    "summBy = summarizeByClass(X_train)\n",
    "print(summBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-125b318f1ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-57bb369d7529>\u001b[0m in \u001b[0;36mgetPredictions\u001b[0;34m(summaries, testSet)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-57bb369d7529>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(summaries, inputVector)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateClassProbabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mbestLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclassValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-57bb369d7529>\u001b[0m in \u001b[0;36mcalculateClassProbabilities\u001b[0;34m(summaries, inputVector)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassSummaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputVector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassValue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcalculateProbability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-57bb369d7529>\u001b[0m in \u001b[0;36mcalculateProbability\u001b[0;34m(x, mean, stdev)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculateProbability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mexponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mexponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "print(getPredictions(summBy,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "Criar uma versão de sua implementação usando as funções disponíveis na biblioteca SciKitLearn para o Naive Bayes ([veja aqui](http://scikit-learn.org/stable/modules/naive_bayes.html)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 7 points : 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(df, df[:,6]).predict(df)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (df.shape[0],(df[:,6] != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
